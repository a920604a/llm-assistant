from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import time
import threading
from datetime import datetime, timedelta
from prometheus_fastapi_instrumentator import Instrumentator
from api.routers import query, user, upload
from storage.qdrant import create_qdrant_collection
from arxiv_ingestion.flows.arxiv_pipeline import arxiv_pipeline
from arxiv_ingestion.db.qdrant import create_qdrant_collection
from arxiv_ingestion.db.minio import create_bucket_if_not_exists

from logger import get_logger

logger = get_logger(__name__)


app = FastAPI()
Instrumentator().instrument(app).expose(app)

origins = ["http://mcpclient:8000"]


# è¨­å®šå…è¨±çš„ä¾†æº
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# REST API routers

app.include_router(query.router, tags=["query"])
app.include_router(user.router, tags=["user"])
app.include_router(upload.router, tags=["upload"])


# ---------------------- Background daily pipeline ----------------------
def daily_pipeline_runner():
    """æ¯å¤©åŸ·è¡Œ Arxiv pipelineï¼Œä¸é˜»å¡ API"""
    while True:
        target_date = (datetime.utcnow() - timedelta(days=10)).strftime("%Y%m%d")
        try:
            logger.info("ğŸ”¹ Running daily Arxiv pipeline...")
            arxiv_pipeline(target_date=target_date, max_results=5, process_pdfs=True)
            logger.info("âœ… Pipeline run completed.")
        except Exception as e:
            logger.exception(f"âŒ Pipeline failed: {e}")

        # ç­‰ä¸€å¤©å†è·‘
        time.sleep(24 * 60 * 60)


# Startup event: ç¢ºä¿ Qdrant å•Ÿå‹•å¾Œå†å»ºç«‹ collection
@app.on_event("startup")
async def startup_event():
    logger.info("Waiting for Qdrant to be ready...")
    max_retry = 10

    for i in range(max_retry):
        try:
            create_qdrant_collection()  # å…§éƒ¨å·²è™•ç†ã€Œå·²å­˜åœ¨ã€æƒ…æ³
            logger.info("âœ… Qdrant collection is ready.")
            break
        except Exception as e:
            logger.warning(f"Qdrant not ready yet ({i+1}/{max_retry}): {e}")
            time.sleep(3)
    else:
        logger.error("âŒ Failed to ensure Qdrant collection after multiple retries.")

    # ğŸ”¹ å•Ÿå‹•æ™‚å…ˆè·‘ä¸€æ¬¡ pipeline
    create_qdrant_collection()
    create_bucket_if_not_exists()
    try:
        target_date = (datetime.utcnow() - timedelta(days=10)).strftime("%Y%m%d")
        logger.info("ğŸ”¹ Running initial Arxiv pipeline at startup...")
        arxiv_pipeline(target_date=target_date, max_results=10, process_pdfs=True)
        logger.info("âœ… Initial pipeline run completed.")
    except Exception as e:
        logger.exception(f"âŒ Initial pipeline failed: {e}")

    # å•Ÿå‹•æ¯å¤© pipeline çš„ background thread
    threading.Thread(target=daily_pipeline_runner, daemon=True).start()
    logger.info("ğŸ”¹ Daily Arxiv pipeline runner started in background.")
