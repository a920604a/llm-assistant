import os
import json
import click
import requests
from typing import List
from prefect import flow, task
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from qdrant_client import QdrantClient, models 
from fastembed import TextEmbedding
from sentence_transformers import SentenceTransformer


# === åŸºæœ¬è¨­å®š ===
OLLAMA_API_URL = "http://localhost:11434"
collection_name = "notes_collection"

# === LangChain ===
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,
    chunk_overlap=150,
    separators=["\n\n", "\n", "ã€‚", "ï¼Œ", " "]
)



def get_embedding(text: str, use_sentence_transformers: bool = True) -> List[float]:
    if use_sentence_transformers:
        model_name = 'uer/sbert-base-chinese-nli'
        model = SentenceTransformer(model_name)
        vector = model.encode([text])  # ä»éœ€åŒ…æˆ list å‚³å…¥
        return vector[0].tolist()      # å–ç¬¬ä¸€ç­†ä¸¦è½‰ list[float]
    else:
        model_name = "BAAI/bge-small-zh-v1.5"
        embedder = TextEmbedding(model_name=model_name)
        return next(embedder.embed([text]))  # generator ä¸­å–å‡ºç¬¬ä¸€ç­†
    
    
# === Qdrant åˆå§‹åŒ– ===
qdrant_client = QdrantClient(url="http://localhost:6333")

# âœ… å»ºç«‹ Collectionï¼ˆè‹¥å°šæœªå»ºç«‹ï¼‰
@task
def ensure_qdrant_collection():
    if collection_name not in [c.name for c in qdrant_client.get_collections().collections]:
        qdrant_client.recreate_collection(
            collection_name=collection_name,
            vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),
        )


# âœ… ç¿»è­¯æ–‡å­—
@task
def ollama_translate(text: str, model: str = "llama2:7b") -> str:
    response = requests.post(
        f"{OLLAMA_API_URL}/api/generate",
        json={
            "model": model,
            "prompt": f"è«‹å¹«æˆ‘å°‡ä»¥ä¸‹å…§å®¹ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼š\n{text}",
            "stream": False,
        },
    )
    response.raise_for_status()
    return response.json()["response"]


# âœ… ç”¢å‡º Metadata
@task
def ollama_generate_metadata(text: str, model: str = "llama3") -> dict:
    meta_prompt = f"""
è«‹é–±è®€ä»¥ä¸‹æ•™å­¸ç­†è¨˜ï¼Œä¸¦åˆ†æå‡ºä»¥ä¸‹å±¬æ€§ï¼š
- ä¸»é¡Œåˆ†é¡ï¼ˆä»¥ä¸€æ®µæ–‡å­—æè¿°ï¼‰
- é©åˆç¨‹åº¦ï¼ˆåˆå­¸è€…ã€ä¸­éšã€é€²éšï¼‰
- ä¸‰å€‹é—œéµå­—

æ•™å­¸å…§å®¹å¦‚ä¸‹ï¼š
{text}
è«‹ç”¨ JSON æ ¼å¼è¼¸å‡ºï¼Œä¾‹å¦‚ï¼š
{{
  "topic": "å¤§æ•¸æ“šæ¶æ§‹è¨­è¨ˆ",
  "level": "ä¸­éš",
  "keywords": ["æ•¸æ“šè½‰å‹", "åˆ†æ•£å¼å„²å­˜", "è³‡æ–™æ¹–"]
}}
"""
    response = requests.post(
        f"{OLLAMA_API_URL}/api/generate",
        json={
            "model": model,
            "prompt": meta_prompt,
            "stream": False,
        },
    )
    response.raise_for_status()
    raw = response.json()["response"]

    try:
        return json.loads(raw)
    except Exception:
        print("âš ï¸ ç„¡æ³•è§£æ metadata JSONï¼Œå›å‚³ç‚ºï¼š", raw)
        return {"topic": "", "level": "", "keywords": []}


# âœ… ä¸»æµç¨‹ï¼šåŒ¯å…¥ç­†è¨˜
@flow(name="Import Markdown Notes")
def import_md_notes_flow(md_text_list: List[str]):
    ensure_qdrant_collection()

    points = []
    idx = 0

    for md_text in md_text_list:
        print(f"â¡ï¸ ç¿»è­¯ä¸­ï¼ˆåŸå§‹å­—æ•¸: {len(md_text)}ï¼‰...")
        translated = ollama_translate(md_text)
        print(f"ç¿»è­¯çµæœ : {translated}")

        print("ğŸ§  ç”¢å‡º Metadata...")
        metadata = ollama_generate_metadata(translated)
        print(f"Metadata çµæœ : {metadata}")

        # print("âœ‚ï¸ åˆ†æ®µä¸­...")
        # chunks = text_splitter.split_text(translated)
        # for chunk in chunks:
        #     vector = embeddings.embed_query(chunk)
        #     payload = {
        #         "text": chunk,
        #         "translated": True,
        #         **metadata,
        #     }
        #     points.append(
        #         models.PointStruct(id=idx, vector=vector, payload=payload)
        #     )
        #     idx += 1

    # print(f"ğŸ“¦ å¯«å…¥ {len(points)} ç­†è³‡æ–™åˆ° Qdrant")
    # qdrant_client.upsert(collection_name=collection_name, points=points)


# âœ… CLI ä»‹é¢ä½¿ç”¨ click
@click.command()
@click.option('--file', type=click.Path(exists=True), required=True, help='Markdown æª”æ¡ˆè·¯å¾‘')
def cli(file):
    with open(file, 'r', encoding='utf-8') as f:
        md_text = f.read()
    import_md_notes_flow([md_text])


if __name__ == "__main__":
    cli()
# python ingest.py --file /ingest/'Chapter 1_ Big Data.md'